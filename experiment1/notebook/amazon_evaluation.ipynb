{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world!\n"
     ]
    }
   ],
   "source": [
    "class StubLogger(object):\n",
    "    def __getattr__(self, name):\n",
    "        return self.log_print\n",
    "\n",
    "    def log_print(self, msg, *args):\n",
    "        print(msg % args)\n",
    "\n",
    "LOGGER = StubLogger()\n",
    "LOGGER.info(\"Hello %s!\", \"world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "import time\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def elapsed_timer(message):\n",
    "    start_time = time.time()\n",
    "    yield\n",
    "    LOGGER.info(message.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hitsAtK(user_ranks, k=10):\n",
    "    return (user_ranks[\"rank\"].notna() & (user_ranks[\"rank\"] <= k)).sum(skipna=True)\n",
    "\n",
    "\n",
    "def precisionAtK(user_ranks, k):\n",
    "    precision = float(hitsAtK(user_ranks, k)) / k\n",
    "    return precision\n",
    "\n",
    "\n",
    "def recallAtK(user_ranks, k):\n",
    "    recall = float(hitsAtK(user_ranks, k)) / user_ranks.shape[0]\n",
    "    return recall\n",
    "\n",
    "\n",
    "def averagePrecisionAtK(user_ranks, k):\n",
    "    user_ranks = user_ranks.sort_values(by=\"rank\")\n",
    "    k_user_ranks = user_ranks.head(min(user_ranks.shape[0], k))\n",
    "    k_correct_user_ranks = k_user_ranks[k_user_ranks[\"rank\"].notna() & (k_user_ranks[\"rank\"] <= k)]\n",
    "\n",
    "    if k_correct_user_ranks.shape[0] > 0:\n",
    "        #print k_correct_user_ranks\n",
    "        score = 0.0\n",
    "        for row in range(k_correct_user_ranks.shape[0]):\n",
    "            tmp_user_ranks = k_correct_user_ranks.head(row + 1)\n",
    "            row_k = k_correct_user_ranks.iloc[row][\"rank\"]\n",
    "            score = score + precisionAtK(tmp_user_ranks, row_k)\n",
    "        avgPrec = float(score) / min(user_ranks.shape[0], k)\n",
    "    else:\n",
    "        avgPrec = 0.0\n",
    "    return avgPrec\n",
    "\n",
    "\n",
    "def ndcgAtK(user_ranks, k):\n",
    "    def dcg(rank):\n",
    "        return 1.0 / np.log2(rank + 1)\n",
    "\n",
    "\n",
    "    user_ranks = user_ranks.sort_values(by=\"rank\")\n",
    "    k_user_ranks = user_ranks.head(min(user_ranks.shape[0], k))\n",
    "    k_ranks = k_user_ranks[k_user_ranks[\"rank\"].notna() & (k_user_ranks[\"rank\"] <= k)][\"rank\"].values\n",
    "\n",
    "    ranks_idcg = dcg(np.arange(1, k_user_ranks.shape[0] + 1))\n",
    "    ranks_dcg = dcg(k_ranks)\n",
    "\n",
    "    ndcg = float(np.sum(ranks_dcg)) / np.sum(ranks_idcg)\n",
    "    return ndcg\n",
    "\n",
    "\n",
    "def topEventsAtK(user_ranks, k):\n",
    "    user_ranks = user_ranks.sort_values(by=\"rank\")\n",
    "    k_user_ranks = user_ranks.head(min(user_ranks.shape[0], k))\n",
    "    return pd.DataFrame({\n",
    "        \"event_id\": k_user_ranks[\"event_id\"].drop_duplicates().sort_values()\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quickMetricsPerUser(user_ranks):\n",
    "    return pd.DataFrame({\n",
    "        \"precision_at_10\": [precisionAtK(user_ranks, 10)],\n",
    "        \"recall_at_10\": [recallAtK(user_ranks, 10)],\n",
    "        \"ndcg_at_10\": [ndcgAtK(user_ranks, 10)],\n",
    "    })\n",
    "\n",
    "\n",
    "def basicMetricsPerUser(user_ranks):\n",
    "    return pd.DataFrame({\n",
    "        \"precision_at_10\": [precisionAtK(user_ranks, 10)],\n",
    "        \"recall_at_10\": [recallAtK(user_ranks, 10)],\n",
    "        \"ndcg_at_50\": [ndcgAtK(user_ranks, 50)],\n",
    "        \"ndcg_at_20\": [ndcgAtK(user_ranks, 20)],\n",
    "        \"ndcg_at_10\": [ndcgAtK(user_ranks, 10)],\n",
    "        \"avg_prec_at_20\": [averagePrecisionAtK(user_ranks, 20)],\n",
    "        \"avg_prec_at_10\": [averagePrecisionAtK(user_ranks, 10)],\n",
    "    })\n",
    "\n",
    "\n",
    "def quadMetricsPerUser(user_ranks):\n",
    "    return pd.DataFrame({\n",
    "        \"precision_at_50\": [precisionAtK(user_ranks, 50)],\n",
    "        \"precision_at_20\": [precisionAtK(user_ranks, 20)],\n",
    "        \"precision_at_10\": [precisionAtK(user_ranks, 10)],\n",
    "        \"precision_at_5\": [precisionAtK(user_ranks, 5)],\n",
    "        \"recall_at_50\": [recallAtK(user_ranks, 50)],\n",
    "        \"recall_at_20\": [recallAtK(user_ranks, 20)],\n",
    "        \"recall_at_10\": [recallAtK(user_ranks, 10)],\n",
    "        \"recall_at_5\": [recallAtK(user_ranks, 5)],\n",
    "        \"ndcg_at_50\": [ndcgAtK(user_ranks, 50)],\n",
    "        \"ndcg_at_20\": [ndcgAtK(user_ranks, 20)],\n",
    "        \"ndcg_at_10\": [ndcgAtK(user_ranks, 10)],\n",
    "        \"ndcg_at_5\": [ndcgAtK(user_ranks, 5)],\n",
    "        \"avg_prec_at_20\": [averagePrecisionAtK(user_ranks, 20)],\n",
    "        \"avg_prec_at_10\": [averagePrecisionAtK(user_ranks, 10)],\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalMetrics(rank_data, *, runMetricsPerUser=None):\n",
    "    if runMetricsPerUser is None:\n",
    "        runMetricsPerUser = basicMetricsPerUser\n",
    "\n",
    "    user_metrics = rank_data.groupby(\"user_id\").apply(runMetricsPerUser)\n",
    "    top_events_at_10 = rank_data.groupby(\"user_id\").apply(topEventsAtK, 10)\n",
    "    top_events_at_20 = rank_data.groupby(\"user_id\").apply(topEventsAtK, 20)\n",
    "\n",
    "    metrics = dict()\n",
    "    # Precision\n",
    "    if \"precision_at_50\" in user_metrics.columns:\n",
    "        precision_50 = user_metrics[\"precision_at_50\"].sum(skipna=True) / user_metrics.shape[0]\n",
    "        metrics[\"precision_at_50\"] = [precision_50]\n",
    "    if \"precision_at_20\" in user_metrics.columns:\n",
    "        precision_20 = user_metrics[\"precision_at_20\"].sum(skipna=True) / user_metrics.shape[0]\n",
    "        metrics[\"precision_at_20\"] = [precision_20]\n",
    "    if \"precision_at_10\" in user_metrics.columns:\n",
    "        precision_10 = user_metrics[\"precision_at_10\"].sum(skipna=True) / user_metrics.shape[0]\n",
    "        metrics[\"precision_at_10\"] = [precision_10]\n",
    "    if \"precision_at_5\" in user_metrics.columns:\n",
    "        precision_5 = user_metrics[\"precision_at_5\"].sum(skipna=True) / user_metrics.shape[0]\n",
    "        metrics[\"precision_at_5\"] = [precision_5]\n",
    "\n",
    "    # Recall\n",
    "    if \"recall_at_50\" in user_metrics.columns:\n",
    "        recall_50 = user_metrics[\"recall_at_50\"].sum(skipna=True) / user_metrics.shape[0]\n",
    "        metrics[\"recall_at_50\"] = [recall_50]\n",
    "    if \"recall_at_20\" in user_metrics.columns:\n",
    "        recall_20 = user_metrics[\"recall_at_20\"].sum(skipna=True) / user_metrics.shape[0]\n",
    "        metrics[\"recall_at_20\"] = [recall_20]\n",
    "    if \"recall_at_10\" in user_metrics.columns:\n",
    "        recall_10 = user_metrics[\"recall_at_10\"].sum(skipna=True) / user_metrics.shape[0]\n",
    "        metrics[\"recall_at_10\"] = [recall_10]\n",
    "    if \"recall_at_5\" in user_metrics.columns:\n",
    "        recall_5 = user_metrics[\"recall_at_5\"].sum(skipna=True) / user_metrics.shape[0]\n",
    "        metrics[\"recall_at_5\"] = [recall_5]\n",
    "\n",
    "    # F1 Score\n",
    "    if \"precision_at_50\" in user_metrics.columns and \"recall_at_50\" in user_metrics.columns:\n",
    "        if precision_50 + recall_50 > 0:\n",
    "            f1_score_50 =  2 * ((precision_50 * recall_50) / (precision_50 + recall_50))\n",
    "        else:\n",
    "            f1_score_50 = 0.0\n",
    "        metrics[\"f1_score_at_50\"] = [f1_score_50]\n",
    "    if \"precision_at_20\" in user_metrics.columns and \"recall_at_20\" in user_metrics.columns:\n",
    "        if precision_20 + recall_20 > 0:\n",
    "            f1_score_20 =  2 * ((precision_20 * recall_20) / (precision_20 + recall_20))\n",
    "        else:\n",
    "            f1_score_20 = 0.0\n",
    "        metrics[\"f1_score_at_20\"] = [f1_score_20]\n",
    "    if \"precision_at_10\" in user_metrics.columns and \"recall_at_10\" in user_metrics.columns:\n",
    "        if precision_10 + recall_10 > 0:\n",
    "            f1_score_10 =  2 * ((precision_10 * recall_10) / (precision_10 + recall_10))\n",
    "        else:\n",
    "            f1_score_10 = 0.0\n",
    "        metrics[\"f1_score_at_10\"] = [f1_score_10]\n",
    "    if \"precision_at_5\" in user_metrics.columns and \"recall_at_5\" in user_metrics.columns:\n",
    "        if precision_5 + recall_5 > 0:\n",
    "            f1_score_5 =  2 * ((precision_5 * recall_5) / (precision_5 + recall_5))\n",
    "        else:\n",
    "            f1_score_5 = 0.0\n",
    "        metrics[\"f1_score_at_5\"] = [f1_score_5]\n",
    "\n",
    "    # NDCG@50\n",
    "    if \"ndcg_at_50\" in user_metrics.columns:\n",
    "        ndcg_50 = user_metrics[\"ndcg_at_50\"].sum(skipna=True) / user_metrics.shape[0]\n",
    "        metrics[\"ndcg_at_50\"] = [ndcg_50]\n",
    "    # NDCG@20\n",
    "    if \"ndcg_at_20\" in user_metrics.columns:\n",
    "        ndcg_20 = user_metrics[\"ndcg_at_20\"].sum(skipna=True) / user_metrics.shape[0]\n",
    "        metrics[\"ndcg_at_20\"] = [ndcg_20]\n",
    "    # NDCG@10\n",
    "    if \"ndcg_at_10\" in user_metrics.columns:\n",
    "        ndcg_10 = user_metrics[\"ndcg_at_10\"].sum(skipna=True) / user_metrics.shape[0]\n",
    "        metrics[\"ndcg_at_10\"] = [ndcg_10]\n",
    "    \n",
    "    if \"ndcg_at_5\" in user_metrics.columns:\n",
    "        ndcg_5 = user_metrics[\"ndcg_at_5\"].sum(skipna=True) / user_metrics.shape[0]\n",
    "        metrics[\"ndcg_at_5\"] = [ndcg_5]\n",
    "    # MAP@20\n",
    "    if \"avg_prec_at_20\" in user_metrics.columns:\n",
    "        map_at_20 = user_metrics[\"avg_prec_at_20\"].sum(skipna=True) / user_metrics.shape[0]\n",
    "        metrics[\"map_at_20\"] = [map_at_20]\n",
    "    # MAP@10\n",
    "    if \"avg_prec_at_10\" in user_metrics.columns:\n",
    "        map_at_10 = user_metrics[\"avg_prec_at_10\"].sum(skipna=True) / user_metrics.shape[0]\n",
    "        metrics[\"map_at_10\"] = [map_at_10]\n",
    "\n",
    "    # Mean Rank (calculated only over the rank_data without NA's)\n",
    "    mean_ranks = rank_data[\"rank\"].mean(skipna=True)\n",
    "    if np.isnan(mean_ranks):\n",
    "        mean_ranks = 0.0\n",
    "    # User Coverage (it cannot be calculated here)\n",
    "    user_coverage = 0.0\n",
    "    # Event Coverage\n",
    "    event_coverage_10 = float(top_events_at_10.drop_duplicates().shape[0]) / rank_data[\"event_id\"].drop_duplicates().shape[0]\n",
    "    event_coverage_20 = float(top_events_at_20.drop_duplicates().shape[0]) / rank_data[\"event_id\"].drop_duplicates().shape[0]\n",
    "\n",
    "    metrics[\"mean_ranks\"] = [mean_ranks]\n",
    "    metrics[\"user_coverage\"] = [user_coverage]\n",
    "    metrics[\"event_coverage_at_10\"] = [event_coverage_10]\n",
    "    metrics[\"event_coverage_at_20\"] = [event_coverage_20]\n",
    "    # This percentage of NA's only affects the mean_ranks metric,\n",
    "    # the other metrics consider the NA's in the calculation\n",
    "    metrics[\"perc_user_events_rank_NA\"] = float(rank_data[\"rank\"].isna().sum()) / rank_data.shape[0]\n",
    "    \n",
    "    return pd.DataFrame(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def definePastRSVPGroups(count_data, new_col_name):\n",
    "    count_data[\"past_rsvps\"] = np.nan\n",
    "    freqs = count_data[\"freq\"]\n",
    "\n",
    "    count_data.loc[freqs <= 0, \"past_rsvps\"] = \"0\"\n",
    "    count_data.loc[freqs <= 1, \"past_rsvps\"] = \"1\"\n",
    "    count_data.loc[freqs <= 2, \"past_rsvps\"] = \"2\"\n",
    "    count_data.loc[freqs <= 3, \"past_rsvps\"] = \"3\"\n",
    "    count_data.loc[freqs <= 4, \"past_rsvps\"] = \"4\"\n",
    "    count_data.loc[freqs <= 5, \"past_rsvps\"] = \"5\"\n",
    "    count_data.loc[(6 <= freqs) & (freqs <= 10), \"past_rsvps\"] = \"6-10\"\n",
    "    count_data.loc[(11 <= freqs) & (freqs <= 20), \"past_rsvps\"] = \"11-20\"\n",
    "    count_data.loc[freqs > 20, \"past_rsvps\"] = \">20\"\n",
    "\n",
    "    count_data[\"past_rsvps\"] = count_data[\"past_rsvps\"].astype(\"category\")\n",
    "    count_data = count_data.rename(columns={\"past_rsvps\": new_col_name})\n",
    "\n",
    "    return count_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluatePartition(object):\n",
    "    def __init__(self, partition_dir, *, \n",
    "                 runMetricsPerUser=None):\n",
    "        self.partition_dir = partition_dir\n",
    "        self.runMetricsPerUser = runMetricsPerUser\n",
    "        if self.runMetricsPerUser is None:\n",
    "            self.runMetricsPerUser = basicMetricsPerUser\n",
    "\n",
    "        self.user_event_rsvp_test_filepath = os.path.join(self.partition_dir, \"user-event-rsvp_test.tsv\")\n",
    "#         self.count_events_per_test_user_filepath = os.path.join(self.partition_dir, \"count_events_per_test-user_train.tsv\")\n",
    "#         self.count_users_per_test_event_filepath = os.path.join(self.partition_dir, \"count_users_per_test-event_train.tsv\")\n",
    "        \n",
    "        self.user_event_rsvps_test = pd.read_csv(self.user_event_rsvp_test_filepath,\n",
    "                                                 sep='\\t', header=None, names=[\"user_id\", \"event_id\"])\n",
    "#         self.count_events_per_test_user = pd.read_csv(self.count_events_per_test_user_filepath,\n",
    "#                                       sep='\\t', header=None, names=[\"user_id\", \"freq\"])\n",
    "#         self.count_users_per_test_event = pd.read_csv(self.count_users_per_test_event_filepath,\n",
    "#                                        sep='\\t', header=None, names=[\"event_id\", \"freq\"])\n",
    "\n",
    "        self.map_user_event_rsvps_test = self._read_map_user_events_test(self.user_event_rsvps_test)\n",
    "#         self.user_count = definePastRSVPGroups(self.count_events_per_test_user, \"user_past_rsvps\")\n",
    "#         self.event_count = definePastRSVPGroups(self.count_users_per_test_event, \"event_past_rsvps\")\n",
    "        \n",
    "        print(\"users: {0}, events: {1}\".format(self.user_event_rsvps_test[\"user_id\"].drop_duplicates().count(),\n",
    "                                               self.user_event_rsvps_test[\"event_id\"].drop_duplicates().count()))\n",
    "        \n",
    "        self.group_evaluations = {\n",
    "            \"partition\": None,\n",
    "            \"partition-user\": None,\n",
    "            \"partition-event\": None,\n",
    "            \"partition-user-event\": None\n",
    "        }\n",
    "\n",
    "    def _read_map_user_events_test(self, user_event_rsvps):\n",
    "        user_events = dict()\n",
    "        for row in user_event_rsvps.itertuples():\n",
    "            user_events.setdefault(row.user_id, set()).add(row.event_id)\n",
    "        return user_events\n",
    "\n",
    "    def add_evaluation(self, recommendation_filepath, group_vars, *,\n",
    "                       partition, algorithm, model_params,\n",
    "                       pre_process_user_id=None, pre_process_event_id=None,\n",
    "                       runMetricsPerUser=None):\n",
    "        if runMetricsPerUser is None:\n",
    "            runMetricsPerUser = self.runMetricsPerUser\n",
    "\n",
    "        relevant_ranks = self._select_relevant_ranks(recommendation_filepath,\n",
    "                                                     pre_process_user_id=pre_process_user_id,\n",
    "                                                     pre_process_event_id=pre_process_event_id)\n",
    "        self._evaluate_ranked_data(relevant_ranks, group_vars,\n",
    "                                   partition=partition, algorithm=algorithm, model_params=model_params,\n",
    "                                   runMetricsPerUser=runMetricsPerUser)\n",
    "\n",
    "    def _select_relevant_ranks(self, recommendation_filepath, *,\n",
    "                               pre_process_user_id=None, pre_process_event_id=None):\n",
    "        if pre_process_user_id is None:\n",
    "            pre_process_user_id = lambda x: x\n",
    "        if pre_process_event_id is None:\n",
    "            pre_process_event_id = lambda x: x\n",
    "\n",
    "        relevant_ranked_user_ids = list()\n",
    "        relevant_ranked_event_ids = list()\n",
    "        relevant_ranks = list()\n",
    "\n",
    "        recommendations = pd.read_csv(recommendation_filepath, sep='\\t',\n",
    "                                      header=None, names=[\"user_id\", \"recommendation\"])\n",
    "        recommendations[\"user_id\"] = pre_process_user_id(recommendations[\"user_id\"])\n",
    "\n",
    "        for row in recommendations.itertuples():\n",
    "            # Get the relevant events per user\n",
    "            new_event_ids_test = self.map_user_event_rsvps_test[row.user_id]\n",
    "            ranked_events = set()\n",
    "\n",
    "            # Check if the model was capable of predicting a ranked list or not\n",
    "            #   There is a predicted value different from ''\n",
    "            if len(row) > 1 and row.recommendation:\n",
    "                ranked_event_list = row.recommendation.split(',')\n",
    "                # Find the relevant events (from new_event_ids_test) in the ranked recommended list and get its ranks\n",
    "                for i, recommendation_str in enumerate(ranked_event_list):\n",
    "                    if ranked_event_list[i]:\n",
    "                        # Separate the new_event_id from the predicted score (use only the 1st one)\n",
    "                        recommendation = recommendation_str.split(':')\n",
    "                        new_event_id = pre_process_event_id(int(recommendation[0]))\n",
    "                        if new_event_id in new_event_ids_test:\n",
    "                            relevant_ranked_user_ids.append(row.user_id)\n",
    "                            relevant_ranked_event_ids.append(new_event_id)\n",
    "                            relevant_ranks.append(i + 1)\n",
    "                            ranked_events.add(new_event_id)\n",
    "\n",
    "            # IDEA: If the Model was not capable of recommeding this event to the user we consider a NA rank\n",
    "            #   * Therefore, we consider ranking larger that limit (e.g. 100) the same as didn't ranking any event to the user\n",
    "            for relevant_event in new_event_ids_test:\n",
    "                if relevant_event not in ranked_events:\n",
    "                    relevant_ranked_user_ids.append(row.user_id)\n",
    "                    relevant_ranked_event_ids.append(relevant_event)\n",
    "                    relevant_ranks.append(np.nan)\n",
    "\n",
    "        return pd.DataFrame({\n",
    "            \"user_id\": relevant_ranked_user_ids,\n",
    "            \"event_id\": relevant_ranked_event_ids,\n",
    "            \"rank\": relevant_ranks\n",
    "        })\n",
    "\n",
    "    def _evaluate_ranked_data(self, relevant_ranks, group_vars, *,\n",
    "                              partition, algorithm, model_params, runMetricsPerUser):\n",
    "        rank_data = relevant_ranks\n",
    "\n",
    "#         rank_data = pd.merge(rank_data, self.user_count[[\"user_id\", \"user_past_rsvps\"]], on=\"user_id\")\n",
    "#         rank_data = pd.merge(rank_data, self.event_count[[\"event_id\", \"event_past_rsvps\"]], on=\"event_id\")\n",
    "#         rank_data = rank_data.sort_values(by=[\"user_past_rsvps\", \"event_past_rsvps\"])\n",
    "\n",
    "        if group_vars == \"partition\":\n",
    "            eval_rank_data = evalMetrics(rank_data, runMetricsPerUser=runMetricsPerUser)\n",
    "#         elif group_vars == \"partition-user\":\n",
    "#             eval_rank_data = rank_data.groupby(\"user_past_rsvps\").apply(evalMetrics, runMetricsPerUser=runMetricsPerUser)\n",
    "#         elif group_vars == \"partition-event\":\n",
    "#             eval_rank_data = rank_data.groupby(\"event_past_rsvps\").apply(evalMetrics, runMetricsPerUser=runMetricsPerUser)\n",
    "#         elif group_vars == \"partition-user-event\":\n",
    "#             eval_rank_data = rank_data.groupby([\"user_past_rsvps\", \"event_past_rsvps\"]).apply(evalMetrics, runMetricsPerUser=runMetricsPerUser)\n",
    "\n",
    "        # Add the partition name\n",
    "        eval_rank_data[\"partition\"] = partition\n",
    "\n",
    "        eval_rank_data[\"algorithm\"] = algorithm\n",
    "\n",
    "        if model_params:\n",
    "            eval_rank_data[\"model_params\"] = model_params\n",
    "        else:\n",
    "            eval_rank_data[\"model_params\"] = np.nan\n",
    "\n",
    "        if self.group_evaluations[group_vars] is None:\n",
    "            self.group_evaluations[group_vars] = pd.DataFrame()\n",
    "        self.group_evaluations[group_vars] = pd.concat([self.group_evaluations[group_vars],\n",
    "                                                        eval_rank_data], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon dataset path combiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amazon_file(*args):\n",
    "    return os.path.join(\"../data/amazon\", *args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users: 305, events: 280\n"
     ]
    }
   ],
   "source": [
    "amazon = EvaluatePartition(\"../data/amazon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- 6.480126142501831s - EGES\n",
      "-- 6.030448913574219s - HAGE\n",
      "-- 6.716273546218872s - DeepWalk\n",
      "-- 6.043151617050171s - LINE1\n",
      "-- 5.714816570281982s - LINE2\n"
     ]
    }
   ],
   "source": [
    "with elapsed_timer(\"-- {0}s - %s\" % (\"EGES\",)):\n",
    "    amazon.add_evaluation(amazon_file(\"EGES.tsv\"), \"partition\", partition=1, algorithm=\"EGES\", model_params=\"EGES\")\n",
    "with elapsed_timer(\"-- {0}s - %s\" % (\"HAGE\",)):\n",
    "    amazon.add_evaluation(amazon_file(\"HAGE.tsv\"), \"partition\", partition=1, algorithm=\"HAGE\", model_params=\"HAGE\")\n",
    "with elapsed_timer(\"-- {0}s - %s\" % (\"DeepWalk\",)):\n",
    "    amazon.add_evaluation(amazon_file(\"deepwalk.tsv\"), \"partition\", partition=1, algorithm=\"DeepWalk\", model_params=\"DeepWalk\")\n",
    "with elapsed_timer(\"-- {0}s - %s\" % (\"LINE-1\",)):\n",
    "    amazon.add_evaluation(amazon_file(\"line1.tsv\"), \"partition\", partition=1, algorithm=\"LINE-1\", model_params=\"LINE-1\")\n",
    "with elapsed_timer(\"-- {0}s - %s\" % (\"LINE-2\",)):\n",
    "    amazon.add_evaluation(amazon_file(\"line2.tsv\"), \"partition\", partition=1, algorithm=\"LINE-2\", model_params=\"LINE-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision_at_10</th>\n",
       "      <th>recall_at_10</th>\n",
       "      <th>f1_score_at_10</th>\n",
       "      <th>ndcg_at_50</th>\n",
       "      <th>ndcg_at_20</th>\n",
       "      <th>ndcg_at_10</th>\n",
       "      <th>map_at_20</th>\n",
       "      <th>map_at_10</th>\n",
       "      <th>mean_ranks</th>\n",
       "      <th>user_coverage</th>\n",
       "      <th>event_coverage_at_10</th>\n",
       "      <th>event_coverage_at_20</th>\n",
       "      <th>perc_user_events_rank_NA</th>\n",
       "      <th>partition</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>model_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.029836</td>\n",
       "      <td>0.295082</td>\n",
       "      <td>0.054193</td>\n",
       "      <td>0.212091</td>\n",
       "      <td>0.198512</td>\n",
       "      <td>0.186436</td>\n",
       "      <td>0.154744</td>\n",
       "      <td>0.151488</td>\n",
       "      <td>27.643678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.435065</td>\n",
       "      <td>1</td>\n",
       "      <td>EGES</td>\n",
       "      <td>EGES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.031475</td>\n",
       "      <td>0.311475</td>\n",
       "      <td>0.057173</td>\n",
       "      <td>0.234762</td>\n",
       "      <td>0.212667</td>\n",
       "      <td>0.207115</td>\n",
       "      <td>0.175350</td>\n",
       "      <td>0.173957</td>\n",
       "      <td>24.425287</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.435065</td>\n",
       "      <td>1</td>\n",
       "      <td>HAGE</td>\n",
       "      <td>HAGE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.025574</td>\n",
       "      <td>0.252459</td>\n",
       "      <td>0.046443</td>\n",
       "      <td>0.176739</td>\n",
       "      <td>0.162557</td>\n",
       "      <td>0.159391</td>\n",
       "      <td>0.130640</td>\n",
       "      <td>0.129849</td>\n",
       "      <td>22.446970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1</td>\n",
       "      <td>DeepWalk</td>\n",
       "      <td>DeepWalk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.024918</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>0.045251</td>\n",
       "      <td>0.176337</td>\n",
       "      <td>0.162954</td>\n",
       "      <td>0.156346</td>\n",
       "      <td>0.129207</td>\n",
       "      <td>0.127404</td>\n",
       "      <td>30.797386</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.503247</td>\n",
       "      <td>1</td>\n",
       "      <td>LINE1</td>\n",
       "      <td>LINE1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.023934</td>\n",
       "      <td>0.236066</td>\n",
       "      <td>0.043462</td>\n",
       "      <td>0.202262</td>\n",
       "      <td>0.190232</td>\n",
       "      <td>0.182998</td>\n",
       "      <td>0.167446</td>\n",
       "      <td>0.165578</td>\n",
       "      <td>24.854962</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.574675</td>\n",
       "      <td>1</td>\n",
       "      <td>LINE2</td>\n",
       "      <td>LINE2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precision_at_10  recall_at_10  f1_score_at_10  ndcg_at_50  ndcg_at_20  \\\n",
       "0         0.029836      0.295082        0.054193    0.212091    0.198512   \n",
       "1         0.031475      0.311475        0.057173    0.234762    0.212667   \n",
       "2         0.025574      0.252459        0.046443    0.176739    0.162557   \n",
       "3         0.024918      0.245902        0.045251    0.176337    0.162954   \n",
       "4         0.023934      0.236066        0.043462    0.202262    0.190232   \n",
       "\n",
       "   ndcg_at_10  map_at_20  map_at_10  mean_ranks  user_coverage  \\\n",
       "0    0.186436   0.154744   0.151488   27.643678            0.0   \n",
       "1    0.207115   0.175350   0.173957   24.425287            0.0   \n",
       "2    0.159391   0.130640   0.129849   22.446970            0.0   \n",
       "3    0.156346   0.129207   0.127404   30.797386            0.0   \n",
       "4    0.182998   0.167446   0.165578   24.854962            0.0   \n",
       "\n",
       "   event_coverage_at_10  event_coverage_at_20  perc_user_events_rank_NA  \\\n",
       "0                   1.0                   1.0                  0.435065   \n",
       "1                   1.0                   1.0                  0.435065   \n",
       "2                   1.0                   1.0                  0.571429   \n",
       "3                   1.0                   1.0                  0.503247   \n",
       "4                   1.0                   1.0                  0.574675   \n",
       "\n",
       "   partition algorithm model_params  \n",
       "0          1      EGES         EGES  \n",
       "1          1      HAGE         HAGE  \n",
       "2          1  DeepWalk     DeepWalk  \n",
       "3          1     LINE1        LINE1  \n",
       "4          1     LINE2        LINE2  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon.group_evaluations[\"partition\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users: 361, events: 291\n"
     ]
    }
   ],
   "source": [
    "douban_proposed = EvaluatePartition(\"../data/douban/baseline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 64\n",
    "h = 256\n",
    "l = str(0.005)[2:]\n",
    "result_dir = \"SAFMmp_ds/shared-attention/F{0}H{1}L{2}B256R001/0314\".format(f, h, l)\n",
    "with elapsed_timer(\"{0}s - %s\" % (result_dir,)):\n",
    "    for e in range(10, 100 + 1, 10):\n",
    "        result_path = os.path.join(result_dir, \"SAFMsatt_F{0}H{1}L{2}B256E{3}R001.tsv\".format(f, h, l, e))\n",
    "        with elapsed_timer(\"-- {0}s - %s\" % (result_path,)):\n",
    "            frappe_safmsatt_ds_ni.add_evaluation(\n",
    "                frappe_file(result_path),\n",
    "                \"partition\", partition=e, algorithm=\"SAFMsatt_ds_ni\", model_params=\"0314F{0}H{1}L{2}B256R001\".format(f, h, l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- 7.423686504364014s - category2vec/number_walks10/walk_length40/representation_size64/window_size5/lambda_factor\n",
      "-- 7.706417798995972s - category2vec/number_walks10/walk_length40/representation_size64/window_size5/lambda_factor\n"
     ]
    }
   ],
   "source": [
    "result_dir = \"category2vec/number_walks10/walk_length40/representation_size64/window_size5/lambda_factor\"\n",
    "with elapsed_timer(\"-- {0}s - %s\" % (result_dir,)):\n",
    "    douban_proposed.add_evaluation(douban_file(result_dir, \"deepwalk.tsv\"), \"partition\", partition=1, algorithm=\"deepwalk\", model_params=\"deepwalk\")\n",
    "with elapsed_timer(\"-- {0}s - %s\" % (result_dir,)):\n",
    "    douban_proposed.add_evaluation(douban_file(result_dir, \"category2vec.tsv\"), \"partition\", partition=1, algorithm=\"category2vec\", model_params=\"category2vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision_at_10</th>\n",
       "      <th>recall_at_10</th>\n",
       "      <th>f1_score_at_10</th>\n",
       "      <th>ndcg_at_50</th>\n",
       "      <th>ndcg_at_20</th>\n",
       "      <th>ndcg_at_10</th>\n",
       "      <th>map_at_20</th>\n",
       "      <th>map_at_10</th>\n",
       "      <th>mean_ranks</th>\n",
       "      <th>user_coverage</th>\n",
       "      <th>event_coverage_at_10</th>\n",
       "      <th>event_coverage_at_20</th>\n",
       "      <th>perc_user_events_rank_NA</th>\n",
       "      <th>partition</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>model_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.031856</td>\n",
       "      <td>0.297784</td>\n",
       "      <td>0.057555</td>\n",
       "      <td>0.253357</td>\n",
       "      <td>0.240939</td>\n",
       "      <td>0.230408</td>\n",
       "      <td>0.208573</td>\n",
       "      <td>0.205665</td>\n",
       "      <td>18.043956</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.522310</td>\n",
       "      <td>1</td>\n",
       "      <td>deepwalk</td>\n",
       "      <td>deepwalk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.040997</td>\n",
       "      <td>0.382271</td>\n",
       "      <td>0.074053</td>\n",
       "      <td>0.309934</td>\n",
       "      <td>0.299201</td>\n",
       "      <td>0.291898</td>\n",
       "      <td>0.260818</td>\n",
       "      <td>0.258657</td>\n",
       "      <td>14.915842</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.469816</td>\n",
       "      <td>1</td>\n",
       "      <td>category2vec</td>\n",
       "      <td>category2vec</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precision_at_10  recall_at_10  f1_score_at_10  ndcg_at_50  ndcg_at_20  \\\n",
       "0         0.031856      0.297784        0.057555    0.253357    0.240939   \n",
       "1         0.040997      0.382271        0.074053    0.309934    0.299201   \n",
       "\n",
       "   ndcg_at_10  map_at_20  map_at_10  mean_ranks  user_coverage  \\\n",
       "0    0.230408   0.208573   0.205665   18.043956            0.0   \n",
       "1    0.291898   0.260818   0.258657   14.915842            0.0   \n",
       "\n",
       "   event_coverage_at_10  event_coverage_at_20  perc_user_events_rank_NA  \\\n",
       "0                   1.0                   1.0                  0.522310   \n",
       "1                   1.0                   1.0                  0.469816   \n",
       "\n",
       "   partition     algorithm  model_params  \n",
       "0          1      deepwalk      deepwalk  \n",
       "1          1  category2vec  category2vec  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "douban_proposed.group_evaluations[\"partition\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
